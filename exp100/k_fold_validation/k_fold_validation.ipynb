{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ca17e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from deezymatch.deezy_match_data_construction import construct_deezymatch_data, generate_test_data\n",
    "from deezymatch.fuzzy_string_matching import run as fuzzy_string_matching\n",
    "from utils.result import result as compute_result\n",
    "\n",
    "from DeezyMatch import train as dm_train\n",
    "from DeezyMatch import inference as dm_inference\n",
    "from DeezyMatch import combine_vecs\n",
    "from DeezyMatch import plot_log\n",
    "from DeezyMatch import candidate_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da84ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(file=\"../data/ground_truth.pkl\", k=5):\n",
    "    master_df = pandas.read_pickle(file) # load 6178 entities\n",
    "\n",
    "    DataFrameDict = {i: pandas.DataFrame() for i in range(0,k)} # key = [0, 9], value dataframe chunks\n",
    "    resultDict = {i: {} for i in range(0,k)}\n",
    "    \n",
    "    try:\n",
    "        offset = round(len(master_df)/k)\n",
    "        for i in range(k):\n",
    "            DataFrameDict[i] = master_df[offset*i:offset*(i+1)]\n",
    "        \n",
    "        for i in range(k):\n",
    "        # for i in [0, 1, 2]:\n",
    "            train_sample = pandas.DataFrame()\n",
    "            test_sample = DataFrameDict[i]\n",
    "            for dict_index in range(0, k):\n",
    "                if dict_index == i:\n",
    "                    continue\n",
    "                train_sample = pandas.concat([train_sample, DataFrameDict[dict_index]], ignore_index=True)\n",
    "\n",
    "            # GENERATE TRAINING DATA\n",
    "            train_sample.to_pickle('data/training_sample.pkl')\n",
    "            construct_deezymatch_data('data/training_sample.pkl',  directory=\"data/\")\n",
    "\n",
    "            # GENERATE TEST DATA\n",
    "            test_sample.to_pickle('data/test_sample.pkl')\n",
    "            generate_test_data('data/test_sample.pkl', directory='data/')\n",
    "            \n",
    "            # train a new model\n",
    "            dm_train(input_file_path=os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                     dataset_path=os.path.join(\"data\", \"name_pairs.txt\"),\n",
    "                     model_name=\"test00\"+str(i))\n",
    "\n",
    "        \n",
    "            # generate vectors for queries (specified in dataset_path) \n",
    "            # using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "            dm_inference(os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                         dataset_path=os.path.join(\"data\", \"queries.txt\"), \n",
    "                         pretrained_model_path=os.path.join(\"models\", \"test00\"+str(i), \"test00\"+str(i)+\".model\"), \n",
    "                         pretrained_vocab_path=os.path.join(\"models\", \"test00\"+str(i), \"test00\"+str(i)+\".vocab\"),\n",
    "                         inference_mode=\"vect\",\n",
    "                         scenario=\"queries/test\")\n",
    "            \n",
    "            # generate vectors for candidates (specified in dataset_path) \n",
    "            # using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "            dm_inference(os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                         dataset_path=os.path.join(\"data\", \"candidates.txt\"), \n",
    "                         pretrained_model_path=os.path.join(\"models\", \"test00\"+str(i), \"test00\"+str(i)+\".model\"), \n",
    "                         pretrained_vocab_path=os.path.join(\"models\", \"test00\"+str(i), \"test00\"+str(i)+\".vocab\"),\n",
    "                         inference_mode=\"vect\",\n",
    "                         scenario=\"candidates/test\")\n",
    "            \n",
    "\n",
    "            # combine vectors stored in queries/test and save them in combined/queries_test\n",
    "            combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "                         input_scenario=os.path.join('queries', 'test'), \n",
    "                         output_scenario=os.path.join('combined', 'queries_test'), \n",
    "                         print_every=10)\n",
    "\n",
    "            combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "                         input_scenario=os.path.join('candidates', 'test'), \n",
    "                         output_scenario=os.path.join('combined', 'candidates_test'), \n",
    "                         print_every=10)\n",
    "\n",
    "            # Select candidates based on L2-norm (aka faiss distance):\n",
    "            # find candidates from candidate_scenario \n",
    "            # for queries specified in query_scenario\n",
    "            candidates_pd = \\\n",
    "                candidate_ranker(query_scenario=os.path.join(\"combined\", \"queries_test\"),\n",
    "                                 candidate_scenario=os.path.join(\"combined\", \"candidates_test\"), \n",
    "                                 ranking_metric=\"faiss\", # two accepted value = ['cosine', faise]\n",
    "                                 selection_threshold=.5, \n",
    "                                 num_candidates=3, \n",
    "                                 search_size=10, \n",
    "                                 verbose=False,\n",
    "                                 use_predict=False,\n",
    "                                 output_path=os.path.join(\"ranker_results\", \"test_candidates_deezymatch\"), \n",
    "                                 pretrained_model_path=os.path.join(\"models\", \"test00\"+str(i), \"test00\"+str(i)+\".model\"), \n",
    "                                 pretrained_vocab_path=os.path.join(\"models\", \"test00\"+str(i), \"test00\"+str(i)+\".vocab\"))\n",
    "\n",
    "            fuzzy_string_matching(os.path.join(\"ranker_results\", \"test_candidates_deezymatch.pkl\"), os.path.join(\"results\", \"result_\"+str(i)+\".pkl\"), directory='data/')\n",
    "\n",
    "            total, retrieved, correct, r, p, f = compute_result(os.path.join(\"results\", \"result_\"+str(i)+\".pkl\"))\n",
    "\n",
    "\n",
    "            result = {'instance': total,\n",
    "                      'retrieved': retrieved, \n",
    "                      'correct': correct, \n",
    "                      'recall': r, \n",
    "                      'precision': p, \n",
    "                      'f-score': f}\n",
    "\n",
    "            resultDict[i] = result\n",
    "    \n",
    "    finally:\n",
    "        with open('resultDict_faiss_3.pickle', 'wb') as handle:\n",
    "            pickle.dump(resultDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    k_fold_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "with open('k_fold_validation/resultDict_faiss_3.pickle', 'rb') as handle:\n",
    "    resultDict = pickle.load(handle)\n",
    "    \n",
    "    total_instance = sum([resultDict[i]['instance'] for i in range(0,k)])\n",
    "    total_retrieved = sum([resultDict[i]['retrieved'] for i in range(0,k)])\n",
    "    total_correct = sum([resultDict[i]['correct'] for i in range(0,k)])\n",
    "    total_recall = sum([resultDict[i]['recall'] for i in range(0,k)])\n",
    "    total_precision = sum([resultDict[i]['precision'] for i in range(0,k)])\n",
    "    total_f_score = sum([resultDict[i]['f-score'] for i in range(0,k)])\n",
    "    \n",
    "    print(f\"{total_instance/k} & {total_retrieved/k} & {total_correct/k} & {total_recall/k} & {total_precision/k} & {total_f_score/k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39deezy)",
   "language": "python",
   "name": "py39deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
