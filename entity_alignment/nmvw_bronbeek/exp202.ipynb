{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29137b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fbb3c",
   "metadata": {},
   "source": [
    "This script takes into consideration of all the NMVW constituent and all the bronbeek constituent and we are looking for n-to-n match. So, maximum number of possible match could be $39567\\times15382$ !\n",
    "\n",
    "Source --> NMVW (39567)\n",
    "\n",
    "Target --> Bronbeek (15382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_pickle(\"../nmvw_data/person_names.pkl\")\n",
    "df2 = pandas.read_csv(\"../data/bronbeek_constituents.csv\", sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d06610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of NMVW data: {df1.shape}\")\n",
    "print(f\"The shape of Bronbeek data: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of NMVW data: {df1.shape}\")\n",
    "print(f\"The shape of Bronbeek data: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb861fe3",
   "metadata": {},
   "source": [
    "# Exact string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchexactstring.match_exact_string import matchExactString\n",
    "\n",
    "result_exact = matchExactString(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed90ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/ExactMatchResults.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(result_exact, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_pickle(\"results/ExactMatchResults.pkl\")\n",
    "df.to_csv(\"results/ExactMatchResults.tsv\", sep=\"\\t\", index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_result import calculate_result\n",
    "ground_truth = pandas.read_csv(\"ground_truth_16_expertsname.tsv\", sep=\"\\t\", index_col=0)\n",
    "calculate_result(df, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f7e18",
   "metadata": {},
   "source": [
    "# Abbreviation Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_pickle(\"../nmvw_data/person_names.pkl\")\n",
    "df2 = pandas.read_csv(\"../data/bronbeek_constituents.csv\", sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchwithabbreviation.match_with_abbreviation import match_with_abbreviation\n",
    "result_abbreviation = match_with_abbreviation(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/AbbreviationMatchResults.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(result_abbreviation, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_pickle(\"results/AbbreviationMatchResults.pkl\")\n",
    "df.to_csv(\"results/AbbreviationMatchResults.tsv\", sep=\"\\t\", index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_result import calculate_result\n",
    "ground_truth = pandas.read_csv(\"ground_truth_16_expertsname.tsv\", sep=\"\\t\", index_col=0)\n",
    "calculate_result(df, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d16a71",
   "metadata": {},
   "source": [
    "# Surname Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_pickle(\"../nmvw_data/person_names.pkl\")\n",
    "df2 = pandas.read_csv(\"../data/bronbeek_constituents.csv\", sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a06cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchsurname.match_surname import matchLastName\n",
    "result_surname = matchLastName(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c074835",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/SurnameMatchResults.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(result_surname, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_pickle(\"results/SurnameMatchResults.pkl\")\n",
    "df.to_csv(\"results/SurnameMatchResults.tsv\", sep=\"\\t\", index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_result import calculate_result\n",
    "ground_truth = pandas.read_csv(\"ground_truth_16_expertsname.tsv\", sep=\"\\t\", index_col=0)\n",
    "calculate_result(df, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8b309",
   "metadata": {},
   "source": [
    "# Fuzzy String Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0200cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_pickle(\"../nmvw_data/person_names.pkl\")\n",
    "df2 = pandas.read_csv(\"../data/bronbeek_constituents.csv\", sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b891402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchfuzzystring.match_fuzzy_string import match_fuzzy_string\n",
    "result_fuzzymatch = match_fuzzy_string(df1, df2, max_score=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/FuzzyStringMatchResults.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(result_fuzzymatch, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_pickle(\"results/FuzzyStringMatchResults.pkl\")\n",
    "df.to_csv(\"results/FuzzyStringMatchResults.tsv\", sep=\"\\t\", index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ba358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_result import calculate_result\n",
    "ground_truth = pandas.read_csv(\"ground_truth_16_expertsname.tsv\", sep=\"\\t\", index_col=0)\n",
    "calculate_result(df, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd2f81",
   "metadata": {},
   "source": [
    "Evaluation on the 16 expert given name can be found [here](evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13053c31",
   "metadata": {},
   "source": [
    "# Deezy Match without Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a365e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1173ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa61823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_pickle(\"../nmvw_data/person_names.pkl\").dropna(subset=[\"pref_label\"]) \n",
    "df1 = df1[df1[\"pref_label\"].apply(lambda x: len(x) > 3)]\n",
    "\n",
    "df2 = pandas.read_csv(\"../data/bronbeek_constituents.csv\", sep=\";\", index_col=0).dropna(subset=[\"FullName\"]) \n",
    "df2 = df2[df2[\"FullName\"].apply(lambda x: len(x) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct query.txt\n",
    "os.remove(\"data/queries.txt\") if os.path.exists(\"data/queries.txt\") else None\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    with open(\"data/queries.txt\", \"a+\") as file:\n",
    "        file.writelines(f\"{row['pref_label']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct candidates.txt\n",
    "os.remove(\"data/candidates.txt\") if os.path.exists(\"data/candidates.txt\") else None\n",
    "\n",
    "for _, row in df2.iterrows():\n",
    "    with open(\"data/candidates.txt\", \"a+\") as file:\n",
    "        file.writelines(f\"{row['FullName']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594faa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for queries (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                         dataset_path=os.path.join(\"data\", \"queries.txt\"), \n",
    "                         pretrained_model_path=os.path.join(\"models\", \"jrc001\", \"jrc001.model\"), \n",
    "                         pretrained_vocab_path=os.path.join(\"models\", \"jrc001\", \"jrc001.vocab\"),\n",
    "                         inference_mode=\"vect\",\n",
    "                         scenario=\"queries/test\")           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c658da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "dm_inference(os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                         dataset_path=os.path.join(\"data\", \"candidates.txt\"), \n",
    "                         pretrained_model_path=os.path.join(\"models\", \"jrc001\", \"jrc001.model\"), \n",
    "                         pretrained_vocab_path=os.path.join(\"models\", \"jrc001\", \"jrc001.vocab\"),\n",
    "                         inference_mode=\"vect\",\n",
    "                         scenario=\"candidates/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in queries/test and save them in combined/queries_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "                         input_scenario=os.path.join('queries', 'test'), \n",
    "                         output_scenario=os.path.join('combined', 'queries_test'), \n",
    "                         print_every=10)\n",
    "\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "                         input_scenario=os.path.join('candidates', 'test'), \n",
    "                         output_scenario=os.path.join('combined', 'candidates_test'), \n",
    "                         print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "candidates_pd = \\\n",
    "                candidate_ranker(query_scenario=os.path.join(\"combined\", \"queries_test\"),\n",
    "                                 candidate_scenario=os.path.join(\"combined\", \"candidates_test\"), \n",
    "                                 ranking_metric=\"faiss\", # two accepted value = ['cosine', faise]\n",
    "                                 selection_threshold=.5, \n",
    "                                 num_candidates=3, \n",
    "                                 search_size=10, \n",
    "                                 verbose=False,\n",
    "                                 use_predict=False,\n",
    "                                 output_path=os.path.join(\"ranker_results\", \"test_candidates_deezymatch\"), \n",
    "                                 pretrained_model_path=os.path.join(\"models\", \"jrc001\", \"jrc001.model\"), \n",
    "                                 pretrained_vocab_path=os.path.join(\"models\", \"jrc001\", \"jrc001.vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358469b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fuzzy_string_matching(source_file, destination_file, directory):\n",
    "\n",
    "    candidate_df = pandas.read_pickle(source_file, compression='infer')\n",
    "    candidate_df = candidate_df[candidate_df['cosine_dist']!={}]\n",
    "    result_table = pandas.DataFrame(columns=df1.columns.tolist() + df2.columns.tolist())\n",
    "    \n",
    "    try:\n",
    "        for i, row in tqdm(candidate_df.iterrows()):\n",
    "            retrieved_uri = []\n",
    "            for candidate_label in row['candidate_original_ids'].keys():\n",
    "                query_index = row['query_original_id']\n",
    "                while True:\n",
    "                    row_1 = df1.iloc[query_index]\n",
    "                    # print(\"I am in while loop 1\")\n",
    "                    if str(row_1['pref_label']) == str(row['query']):\n",
    "                        # print(\"about to break while loop 1\")\n",
    "                        break\n",
    "                    else:\n",
    "                        query_index += 1\n",
    "                \n",
    "                candidate_index = row['candidate_original_ids'][candidate_label]\n",
    "                while True:\n",
    "                    try:\n",
    "                        row_2 = df2.iloc[candidate_index]\n",
    "                        if str(row_2['FullName']) == str(candidate_label):\n",
    "                            # print(\"about to break while loop 2\")\n",
    "                            break\n",
    "                        else:\n",
    "                            candidate_index += 1\n",
    "                    except IndexError:\n",
    "                        print(f\"Ran out of index for {candidate_label}\")\n",
    "                    \n",
    "                # print(\"out of both loops\")\n",
    "                row = row_1.append(row_2)\n",
    "                # print(row)\n",
    "                result_table = result_table.append(row, ignore_index=True)\n",
    "    \n",
    "    finally:\n",
    "        result_table.to_pickle(destination_file)\n",
    "\n",
    "fuzzy_string_matching(os.path.join(\"ranker_results\", \"test_candidates_deezymatch.pkl\"), os.path.join(\"results\", \"result_deezy.pkl\"), directory='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.read_pickle(\"ranker_results/test_candidates_deezymatch.pkl\")\n",
    "\n",
    "result[result['cosine_dist']!={}][:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a241655",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_pickle(os.path.join(\"results\", \"result_deezy.pkl\"))[276:296]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4774726",
   "metadata": {},
   "source": [
    "# Deezy Match after Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4154ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58891b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2675ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_pickle(\"../nmvw_data/person_names.pkl\").dropna(subset=[\"pref_label\"]) \n",
    "df1 = df1[df1[\"pref_label\"].apply(lambda x: len(x) > 3)]\n",
    "\n",
    "df2 = pandas.read_csv(\"../data/bronbeek_constituents.csv\", sep=\";\", index_col=0).dropna(subset=[\"FullName\"]) \n",
    "df2 = df2[df2[\"FullName\"].apply(lambda x: len(x) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aed712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct query.txt\n",
    "os.remove(\"data/queries.txt\") if os.path.exists(\"data/queries.txt\") else None\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    with open(\"data/queries.txt\", \"a+\") as file:\n",
    "        file.writelines(f\"{row['pref_label']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct candidates.txt\n",
    "os.remove(\"data/candidates.txt\") if os.path.exists(\"data/candidates.txt\") else None\n",
    "\n",
    "for _, row in df2.iterrows():\n",
    "    with open(\"data/candidates.txt\", \"a+\") as file:\n",
    "        file.writelines(f\"{row['FullName']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fcb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# generate vectors for queries (specified in dataset_path) \n",
    "# using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "dm_inference(os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                         dataset_path=os.path.join(\"data\", \"queries.txt\"), \n",
    "                         pretrained_model_path=os.path.join(\"models\", \"finetuned_001\", \"finetuned_001.model\"), \n",
    "                         pretrained_vocab_path=os.path.join(\"models\", \"finetuned_001\", \"finetuned_001.vocab\"),\n",
    "                         inference_mode=\"vect\",\n",
    "                         scenario=\"queries/test\")           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "dm_inference(os.path.join(\"inputs\", \"input_dfm.yaml\"),\n",
    "                         dataset_path=os.path.join(\"data\", \"candidates.txt\"), \n",
    "                         pretrained_model_path=os.path.join(\"models\", \"finetuned_001\", \"finetuned_001.model\"), \n",
    "                         pretrained_vocab_path=os.path.join(\"models\", \"finetuned_001\", \"finetuned_001.vocab\"),\n",
    "                         inference_mode=\"vect\",\n",
    "                         scenario=\"candidates/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefaa28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import combine_vecs\n",
    "\n",
    "# combine vectors stored in queries/test and save them in combined/queries_test\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "                         input_scenario=os.path.join('queries', 'test'), \n",
    "                         output_scenario=os.path.join('combined', 'queries_test'), \n",
    "                         print_every=10)\n",
    "\n",
    "combine_vecs(rnn_passes=['fwd', 'bwd'], \n",
    "                         input_scenario=os.path.join('candidates', 'test'), \n",
    "                         output_scenario=os.path.join('combined', 'candidates_test'), \n",
    "                         print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "candidates_pd = \\\n",
    "                candidate_ranker(query_scenario=os.path.join(\"combined\", \"queries_test\"),\n",
    "                                 candidate_scenario=os.path.join(\"combined\", \"candidates_test\"), \n",
    "                                 ranking_metric=\"faiss\", # two accepted value = ['cosine', faise]\n",
    "                                 selection_threshold=.5, \n",
    "                                 num_candidates=3, \n",
    "                                 search_size=10, \n",
    "                                 verbose=False,\n",
    "                                 use_predict=False,\n",
    "                                 output_path=os.path.join(\"ranker_results\", \"test_candidates_deezymatch\"), \n",
    "                                 pretrained_model_path=os.path.join(\"models\", \"finetuned_001\", \"finetuned_001.model\"), \n",
    "                                 pretrained_vocab_path=os.path.join(\"models\", \"finetuned_001\", \"finetuned_001.vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cac2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fuzzy_string_matching(source_file, destination_file, directory):\n",
    "\n",
    "    candidate_df = pandas.read_pickle(source_file, compression='infer')[result['cosine_dist']!={}]\n",
    "    result_table = pandas.DataFrame(columns=df1.columns.tolist() + df2.columns.tolist())\n",
    "    \n",
    "    try:\n",
    "        for i, row in tqdm(candidate_df.iterrows()):\n",
    "            retrieved_uri = []\n",
    "            for candidate_id in row['candidate_original_ids'].values():\n",
    "                row_1 = df1.iloc[row['query_original_id']]\n",
    "                row_2 = df2.iloc[candidate_id]\n",
    "                row = row_1.append(row_2)\n",
    "                result_table = result_table.append(row, ignore_index=True)\n",
    "\n",
    "    finally:\n",
    "        result_table.to_pickle(destination_file)\n",
    "\n",
    "fuzzy_string_matching(os.path.join(\"ranker_results\", \"test_candidates_deezymatch.pkl\"), os.path.join(\"results\", \"FinetunedDeezyMatchResults.pkl\"), directory='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_pickle(os.path.join(\"results\", \"FinetunedDeezyMatchResults.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd98c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.read_pickle(os.path.join(\"ranker_results\", \"test_candidates_deezymatch.pkl\"))\n",
    "result[result['cosine_dist']!={}][:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
